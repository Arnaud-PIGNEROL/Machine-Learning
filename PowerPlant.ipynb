{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PowerPlant Dataset : Arnaud PIGNEROL & Louis TARDY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation of libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtention of the excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"..\\CCPP\\Folds5x2_pp.xlsx\", sheet_name = None)\n",
    "df = pd.concat(df, axis = 0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We have to normalize our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>V</th>\n",
       "      <th>AP</th>\n",
       "      <th>RH</th>\n",
       "      <th>PE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.372521</td>\n",
       "      <td>0.291815</td>\n",
       "      <td>0.771591</td>\n",
       "      <td>0.638204</td>\n",
       "      <td>0.569536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.662040</td>\n",
       "      <td>0.669039</td>\n",
       "      <td>0.671863</td>\n",
       "      <td>0.449330</td>\n",
       "      <td>0.319338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.093484</td>\n",
       "      <td>0.249822</td>\n",
       "      <td>0.476862</td>\n",
       "      <td>0.892493</td>\n",
       "      <td>0.904636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.539660</td>\n",
       "      <td>0.568683</td>\n",
       "      <td>0.429349</td>\n",
       "      <td>0.684718</td>\n",
       "      <td>0.347285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.255241</td>\n",
       "      <td>0.216014</td>\n",
       "      <td>0.404355</td>\n",
       "      <td>0.952547</td>\n",
       "      <td>0.710464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         AT         V        AP        RH        PE\n",
       "0  0.372521  0.291815  0.771591  0.638204  0.569536\n",
       "1  0.662040  0.669039  0.671863  0.449330  0.319338\n",
       "2  0.093484  0.249822  0.476862  0.892493  0.904636\n",
       "3  0.539660  0.568683  0.429349  0.684718  0.347285\n",
       "4  0.255241  0.216014  0.404355  0.952547  0.710464"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalizeFeature(df):\n",
    "    normalized = (df - df.min()) / (df.max() - df.min())\n",
    "    df.update(normalized)\n",
    "\n",
    "\n",
    "normalizeFeature(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we can extract our values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['AT', 'V', 'AP', 'RH']]\n",
    "y = df[['PE']]\n",
    "\n",
    "n = len(x.axes[1]) # n is the number of observations = 4\n",
    "m = len(x.axes[0]) # m is the number of features = 47840\n",
    "\n",
    "X = np.c_[np.ones((m, 1), dtype = float), x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We have to implement the vector of weights w\n",
    "### Because we do not have weights yet we instantiate it at 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.ones((n + 1, 1))\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We have to implement the cost function J\n",
    "$ J_w =\\frac {1}{2m} * \\sum (h_w(x^i) - y^i)² $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.815852728463007]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cost = []\n",
    "def costFunction(w, X, y):    \n",
    "    hw = np.dot(X, w)\n",
    "    val = hw - y\n",
    "    val2 = val ** 2\n",
    "    somme = np.sum(val2)\n",
    "    \n",
    "    result = somme / (2 * len(y))\n",
    "    return result[0]\n",
    "\n",
    "J = costFunction(w, X, y)\n",
    "Cost.append(costFunction(w, X, y))\n",
    "Cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We have to implement the Gradient Descent\n",
    "$ w_k = w_k - \\frac {\\alpha}{m} * \\sum (h_w(x^i) - y^i) * x_k $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha reduced :  0.0075\n",
      "alpha reduced :  0.001875\n",
      "alpha reduced :  0.00046875\n",
      "alpha reduced :  0.0001171875\n",
      "alpha reduced :  2.9296875e-05\n",
      "alpha reduced :  7.32421875e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.70497643],\n",
       "       [-1.6595034 ],\n",
       "       [ 0.19364774],\n",
       "       [-0.39622948],\n",
       "       [-0.48742235]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient = np.zeros((n + 1, 1))\n",
    "def gradientDescent(w, X, y):    \n",
    "    \n",
    "    max_iterations = 1000\n",
    "    delta = 0.000000001\n",
    "    alpha = 0.03\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        tmp = w\n",
    "        \n",
    "        hw = np.dot(X, w)\n",
    "        val = hw - y\n",
    "        gradient = np.dot(X.transpose(), val)\n",
    "        \n",
    "        w = tmp - gradient * alpha\n",
    "        \n",
    "        errN = costFunction(w, X, y)\n",
    "        errPrev = Cost[-1]\n",
    "        Cost.append(errN)\n",
    "        \n",
    "        if(np.abs(errN - errPrev) < delta):\n",
    "            print(\"Done\\n\", errN, \"\\n\", errPrev)\n",
    "            break\n",
    "            \n",
    "        if(errN > errPrev):\n",
    "            alpha = alpha / n\n",
    "            print(\"alpha reduced : \", alpha)\n",
    "        \n",
    "    return w\n",
    "\n",
    "\n",
    "w = gradientDescent(w, X, y)\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Once you build a good model with your from-scratch implementation, build a new model with Scikit-Learn and compare the obtained results.\n",
    "### Comparaison to the result obtain with Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta coef : [[ 1.09191426 -0.9245856  -0.17412057  0.03322877 -0.15617001]]\n",
      "w            [[ 1.70497643 -1.6595034   0.19364774 -0.39622948 -0.48742235]]\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "model.coef_\n",
    "model.intercept_\n",
    "model.coef_[0][0] = model.intercept_\n",
    "\n",
    "print(\"theta coef : {0}\".format(model.coef_))\n",
    "print(\"w           \", w.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the following functions to your library to calculate R2, MAE, RMSE\n",
    "### 1. meanAbsoluteError()\n",
    "$ mae = \\frac {1}{N} * \\sum |y_i - \\bar{y}| $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07362888305826783\n"
     ]
    }
   ],
   "source": [
    "# MAE\n",
    "def meanAbsoluteError(predicted, y):\n",
    "    return ((np.abs(y - predicted)).sum() / len(y))[0]\n",
    "\n",
    "\n",
    "\n",
    "mae = meanAbsoluteError(np.dot(X, w), y)\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. rootMeanSquaredError()\n",
    "$ rmse = \\sqrt{ \\frac {1}{N} * \\sum (y_i - \\hat{y})²} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09331990200063878\n"
     ]
    }
   ],
   "source": [
    "# RMSE\n",
    "def rootMeanSquaredError(predicted, y):\n",
    "    return (math.sqrt(np.sum((y - predicted) ** 2) / len(y)))\n",
    "\n",
    "\n",
    "rmse = rootMeanSquaredError(np.dot(X, w), y)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. r2()\n",
    "$ r² = 1 - \\frac {\\sum (y_i - \\hat{y})²} {\\sum (y_i - \\bar{y})²} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8295591381673992\n"
     ]
    }
   ],
   "source": [
    "# R2\n",
    "def R2(predicted, y):\n",
    "    \n",
    "    # numerator\n",
    "    error = (y - predicted) ** 2\n",
    "    error2 = np.sum(error)[0]\n",
    "    \n",
    "    # denomirator\n",
    "    mean = y.mean()\n",
    "    variance = (y - mean) ** 2\n",
    "    variance2 = np.sum(variance)[0]\n",
    "    \n",
    "    return (1 - (error2 / variance2))\n",
    "\n",
    "\n",
    "\n",
    "r2 = R2(np.dot(X, w), y)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use LinearRegression from sklearn.linear_model to build a new linear model\n",
    "### Compare the obtained R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8552083951559957\n",
      "0.8295591381673992\n"
     ]
    }
   ],
   "source": [
    "clf = LinearRegression()\n",
    "clf.fit(np.dot(X, w), y)\n",
    "\n",
    "print(clf.score(np.dot(X, w), y))\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a function to calculate the optimal values of wi using the normal equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### normal_equation = $ \\theta_0 + \\theta_1 * y_1 + ... $\n",
    "#### using $ \\theta = inv(X^T * X) * (X^T * y) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.09191426]\n",
      " [-0.9245856 ]\n",
      " [-0.17412057]\n",
      " [ 0.03322877]\n",
      " [-0.15617001]]\n"
     ]
    }
   ],
   "source": [
    "def normalEquation(X, y):\n",
    "    return np.dot(np.linalg.inv(np.dot(X.transpose(), X)), np.dot(X.transpose(), y))\n",
    "\n",
    "normalEq = normalEquation(X, y)\n",
    "print(normalEq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare w from the normal equation and from the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w        [[ 1.06234424 -0.88396279 -0.19690041  0.05173624 -0.13846393]]\n",
      "normalEq [[ 1.09191426 -0.9245856  -0.17412057  0.03322877 -0.15617001]]\n"
     ]
    }
   ],
   "source": [
    "print(\"w       \", w.transpose())\n",
    "print(\"normalEq\", normalEq.transpose())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
